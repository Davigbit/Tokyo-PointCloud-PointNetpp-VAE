{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ah0IzojMNtvL",
    "outputId": "56f78ee3-8c57-4510-fc22-7a087b759dbc"
   },
   "id": "ah0IzojMNtvL",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Augmentation",
   "id": "5a2384f1ee94995e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Method #1",
   "id": "63c62a82dfc2da4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T18:48:32.644217Z",
     "start_time": "2025-02-06T18:48:32.643216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Augmentation functions\n",
    "# ------------------------------------------------\n",
    "\n",
    "def random_rotation(points):\n",
    "    \"\"\"\n",
    "    Apply a random rotation about a random axis in 3D.\n",
    "    points: (N, 3) numpy array\n",
    "    return: rotated points (N, 3)\n",
    "    \"\"\"\n",
    "    # Generate random angles for rotations about X, Y, Z\n",
    "    rx = np.random.uniform(0, 2*np.pi)\n",
    "    ry = np.random.uniform(0, 2*np.pi)\n",
    "    rz = np.random.uniform(0, 2*np.pi)\n",
    "\n",
    "    # Rotation matrices for each axis\n",
    "    Rx = np.array([\n",
    "        [1,           0,            0],\n",
    "        [0,  np.cos(rx), -np.sin(rx)],\n",
    "        [0,  np.sin(rx),  np.cos(rx)]\n",
    "    ])\n",
    "    Ry = np.array([\n",
    "        [ np.cos(ry), 0,  np.sin(ry)],\n",
    "        [          0, 1,           0],\n",
    "        [-np.sin(ry), 0,  np.cos(ry)]\n",
    "    ])\n",
    "    Rz = np.array([\n",
    "        [ np.cos(rz), -np.sin(rz), 0],\n",
    "        [ np.sin(rz),  np.cos(rz), 0],\n",
    "        [          0,           0, 1]\n",
    "    ])\n",
    "\n",
    "    # Combined rotation\n",
    "    R = Rz @ Ry @ Rx\n",
    "    return points @ R.T\n",
    "\n",
    "\n",
    "def random_scaling(points, scale_range=(0.8, 1.2)):\n",
    "    \"\"\"\n",
    "    Scale the point cloud by a random factor.\n",
    "    scale_range: (min_scale, max_scale)\n",
    "    return: scaled points (N, 3)\n",
    "    \"\"\"\n",
    "    scale_factor = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    return points * scale_factor\n",
    "\n",
    "\n",
    "def random_jitter(points, sigma=0.01, clip=0.05):\n",
    "    \"\"\"\n",
    "    Jitter each point by Gaussian noise (mean=0, std=sigma) clipped to +/- clip.\n",
    "    return: jittered points (N, 3)\n",
    "    \"\"\"\n",
    "    jitter = np.clip(sigma * np.random.randn(*points.shape), -clip, clip)\n",
    "    return points + jitter\n",
    "\n",
    "\n",
    "def random_mixup(pc1, pc2, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Mixup: randomly merge points from two point clouds.\n",
    "    alpha ~ fraction from pc1 or ratio if you want partial merges.\n",
    "    Here we take alpha% of points from pc1 and (1-alpha)% from pc2.\n",
    "    \"\"\"\n",
    "    n1 = int(len(pc1) * alpha)\n",
    "    n2 = 4096 - n1  # ensuring total 4096\n",
    "    # Randomly sample points from pc1, pc2\n",
    "    idx1 = np.random.choice(len(pc1), n1, replace=(n1 > len(pc1)))\n",
    "    idx2 = np.random.choice(len(pc2), n2, replace=(n2 > len(pc2)))\n",
    "    return np.concatenate([pc1[idx1], pc2[idx2]], axis=0)\n",
    "\n",
    "\n",
    "def random_cutmix(pc1, pc2):\n",
    "    \"\"\"\n",
    "    CutMix for point clouds (conceptually):\n",
    "    1. Random bounding box on pc1\n",
    "    2. Replace those points by points from pc2 within a bounding box.\n",
    "    Return combined pc with same number of points.\n",
    "    \"\"\"\n",
    "    # For demonstration, let's randomly choose half the points from pc1\n",
    "    # that lie within a random bounding region, and replace them with\n",
    "    # an equal number of points from pc2 in the same bounding region.\n",
    "    N = 4096\n",
    "    # First sample both to 4096 (if they aren't already)\n",
    "    pc1_sample = uniform_resample(pc1, N)\n",
    "    pc2_sample = uniform_resample(pc2, N)\n",
    "\n",
    "    # Random bounding box (small cube) in pc1:\n",
    "    center = np.mean(pc1_sample, axis=0)\n",
    "    offset = np.random.uniform(low=0.0, high=0.1, size=3)\n",
    "    min_box = center - offset\n",
    "    max_box = center + offset\n",
    "\n",
    "    # Indices in pc1 that lie inside the bounding box\n",
    "    inside_box = np.all((pc1_sample >= min_box) & (pc1_sample <= max_box), axis=1)\n",
    "    inside_count = np.sum(inside_box)\n",
    "\n",
    "    # Indices in pc2 to replace them\n",
    "    idx_replace = np.random.choice(len(pc2_sample), inside_count, replace=(inside_count>len(pc2_sample)))\n",
    "\n",
    "    # Output\n",
    "    pc_out = pc1_sample.copy()\n",
    "    pc_out[inside_box] = pc2_sample[idx_replace]\n",
    "    return pc_out\n",
    "\n",
    "\n",
    "def elastic_distortion(points, granularity=0.2, magnitude=0.4):\n",
    "    \"\"\"\n",
    "    Simple approximation of elastic distortion:\n",
    "    1. Generate random 3D displacement fields (Perlin noise or random).\n",
    "    2. Shift points accordingly.\n",
    "    Here, we do a simple random displacement for demonstration.\n",
    "    \"\"\"\n",
    "    # For a more realistic approach, you'd sample from a coherent noise function.\n",
    "    # We'll do a simpler random offset approach grouped by 'granularity'.\n",
    "    # This is very simplistic. \n",
    "    coords = points / granularity\n",
    "    coords_floor = np.floor(coords).astype(np.int32)\n",
    "    offsets = {}\n",
    "    distorted_points = []\n",
    "\n",
    "    for i, c in enumerate(coords_floor):\n",
    "        c_key = tuple(c)\n",
    "        if c_key not in offsets:\n",
    "            offsets[c_key] = np.random.uniform(-magnitude, magnitude, size=3)\n",
    "        distorted_points.append(points[i] + offsets[c_key])\n",
    "\n",
    "    return np.array(distorted_points)\n",
    "\n",
    "\n",
    "def occlusion_simulation(points, drop_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Randomly simulate occlusion by removing a fraction of points \n",
    "    (e.g. all points in some random bounding region).\n",
    "    \"\"\"\n",
    "    N = len(points)\n",
    "    # We remove (drop_ratio * N) points in a random bounding region\n",
    "    # Example: remove points within a random sphere\n",
    "    center_idx = np.random.choice(N, 1)\n",
    "    center = points[center_idx]\n",
    "    radius = np.random.uniform(0.1, 0.3)\n",
    "\n",
    "    dist = np.linalg.norm(points - center, axis=1)\n",
    "    inside_sphere = dist < radius\n",
    "\n",
    "    # If fewer points are inside than we want to remove, \n",
    "    # we might remove them all; otherwise remove only portion.\n",
    "    num_remove = int(drop_ratio * N)\n",
    "    inside_indices = np.where(inside_sphere)[0]\n",
    "\n",
    "    if len(inside_indices) <= num_remove:\n",
    "        # Remove them all\n",
    "        keep_mask = ~inside_sphere\n",
    "    else:\n",
    "        # Random subset of inside_sphere\n",
    "        remove_indices = np.random.choice(inside_indices, num_remove, replace=False)\n",
    "        keep_mask = np.ones(N, dtype=bool)\n",
    "        keep_mask[remove_indices] = False\n",
    "\n",
    "    return points[keep_mask]\n",
    "\n",
    "\n",
    "def uniform_resample(points, num_samples=4096):\n",
    "    \"\"\"\n",
    "    Uniformly (randomly) sample (or downsample) points to a fixed number.\n",
    "    If points < num_samples, replicate some points.\n",
    "    \"\"\"\n",
    "    N = len(points)\n",
    "    if N > num_samples:\n",
    "        # Downsample\n",
    "        idx = np.random.choice(N, num_samples, replace=False)\n",
    "        return points[idx]\n",
    "    elif N < num_samples:\n",
    "        # Upsample\n",
    "        idx = np.random.choice(N, num_samples, replace=True)\n",
    "        return points[idx]\n",
    "    else:\n",
    "        return points\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Main pipeline that applies all augmentations\n",
    "# ------------------------------------------------\n",
    "\n",
    "def augment_point_cloud(pc, all_pcs):\n",
    "    \"\"\"\n",
    "    A demonstration pipeline that does:\n",
    "    1) Random rotation\n",
    "    2) Random scaling\n",
    "    3) Random jitter\n",
    "    4) Optionally MixUp with another random cloud\n",
    "    5) Optionally CutMix with another random cloud\n",
    "    6) Elastic Distortion\n",
    "    7) Occlusion Simulation\n",
    "    8) Resample to 4096\n",
    "    \"\"\"\n",
    "    # 1) Rotate\n",
    "    pc = random_rotation(pc)\n",
    "    # 2) Scale\n",
    "    pc = random_scaling(pc)\n",
    "    # 3) Jitter\n",
    "    pc = random_jitter(pc)\n",
    "\n",
    "    # 4) MixUp with probability 0.5\n",
    "    if random.random() < 0.5 and len(all_pcs) > 1:\n",
    "        # pick a different random cloud\n",
    "        pc2 = random.choice(all_pcs)\n",
    "        if not np.array_equal(pc2, pc):\n",
    "            pc2 = uniform_resample(pc2, 4096)\n",
    "            pc = random_mixup(uniform_resample(pc, 4096), pc2)\n",
    "\n",
    "    # 5) CutMix with probability 0.5\n",
    "    if random.random() < 0.5 and len(all_pcs) > 1:\n",
    "        pc2 = random.choice(all_pcs)\n",
    "        if not np.array_equal(pc2, pc):\n",
    "            pc = random_cutmix(pc, pc2)\n",
    "\n",
    "    # 6) Elastic Distortion\n",
    "    pc = elastic_distortion(pc)\n",
    "\n",
    "    # 7) Occlusion Simulation (with probability 0.5)\n",
    "    if random.random() < 0.5:\n",
    "        pc = occlusion_simulation(pc, drop_ratio=0.2)\n",
    "\n",
    "    # 8) Always resample to 4096 at the end\n",
    "    pc = uniform_resample(pc, 4096)\n",
    "\n",
    "    return pc\n",
    "\n",
    "def load_ply_as_numpy(filepath):\n",
    "    \"\"\"\n",
    "    Load a .ply file using Open3D and return Nx3 numpy array of points.\n",
    "    \"\"\"\n",
    "    pcd = o3d.io.read_point_cloud(filepath)\n",
    "    return np.asarray(pcd.points)\n",
    "\n",
    "def save_numpy_as_ply(points, filepath):\n",
    "    \"\"\"\n",
    "    Save an Nx3 numpy array of points to PLY using Open3D.\n",
    "    \"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    o3d.io.write_point_cloud(filepath, pcd)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Main entry point\n",
    "# ------------------------------------------------\n",
    "\n",
    "def main(input_folder=r'buildings_pointcloud_ply',\n",
    "         output_folder=r'augmented_buildings_ply'):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Gather all PLY files in input folder\n",
    "    ply_files = [f for f in os.listdir(input_folder) if f.endswith('.ply')]\n",
    "\n",
    "    # Pre-load all point clouds into memory for potential MixUp/CutMix\n",
    "    all_point_clouds = []\n",
    "    for fname in ply_files:\n",
    "        full_path = os.path.join(input_folder, fname)\n",
    "        pc = load_ply_as_numpy(full_path)\n",
    "        all_point_clouds.append(pc)\n",
    "\n",
    "    # Augment each file\n",
    "    for i, fname in enumerate(ply_files):\n",
    "        input_path = os.path.join(input_folder, fname)\n",
    "        output_path = os.path.join(output_folder,\"aug_\"+fname)\n",
    "\n",
    "        # Load\n",
    "        pc = all_point_clouds[i]\n",
    "\n",
    "        # Augment\n",
    "        pc_aug = augment_point_cloud(pc, all_point_clouds)\n",
    "\n",
    "        # Save\n",
    "        save_numpy_as_ply(pc_aug, output_path)\n",
    "        print(f\"Saved augmented point cloud to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "bb388be79aa5969d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Method 2",
   "id": "a5645e8d6e5ee0f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import random\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = \"buildings_pointcloud_ply\"\n",
    "output_dir = \"augmented_v2_buildings_ply\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def load_point_cloud(file_path):\n",
    "    pcd = o3d.io.read_point_cloud(file_path)\n",
    "    points = np.asarray(pcd.points)\n",
    "    return points, pcd\n",
    "\n",
    "def save_point_cloud(points, template_pcd, output_path):\n",
    "    template_pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    o3d.io.write_point_cloud(output_path, template_pcd)\n",
    "\n",
    "def random_rotation(points):\n",
    "    rot = R.random().as_matrix()\n",
    "    return points @ rot.T\n",
    "\n",
    "def random_scaling(points, scale_range=(0.8, 1.2)):\n",
    "    scale = np.random.uniform(*scale_range)\n",
    "    return points * scale\n",
    "\n",
    "def random_jittering(points, sigma=0.02, clip=0.05):\n",
    "    jitter = np.clip(np.random.normal(0, sigma, points.shape), -clip, clip)\n",
    "    return points + jitter\n",
    "\n",
    "def mixup(points1, points2):\n",
    "    alpha = np.random.beta(0.4, 0.4)  # Mixup parameter\n",
    "    mixed_points = alpha * points1 + (1 - alpha) * points2\n",
    "    return mixed_points\n",
    "\n",
    "def cutmix(points1, points2):\n",
    "    mask = np.random.rand(points1.shape[0]) > 0.5\n",
    "    mixed_points = np.where(mask[:, None], points1, points2)\n",
    "    return mixed_points\n",
    "\n",
    "def elastic_distortion(points, sigma=0.2, magnitude=0.2):\n",
    "    noise = np.random.randn(*points.shape) * sigma\n",
    "    smoothed_noise = gaussian_filter(noise, sigma=magnitude, mode='constant')\n",
    "    return points + smoothed_noise\n",
    "\n",
    "def occlusion_simulation(points, occlusion_ratio=0.2):\n",
    "    keep_indices = np.random.choice(points.shape[0], int((1 - occlusion_ratio) * points.shape[0]), replace=False)\n",
    "    return points[keep_indices]\n",
    "\n",
    "# Process each PLY file in the directory\n",
    "file_list = [f for f in os.listdir(input_dir) if f.endswith(\".ply\")]\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(input_dir, file_name)\n",
    "    points, pcd_template = load_point_cloud(file_path)\n",
    "\n",
    "    # Perform augmentations\n",
    "    augmented_variants = {\n",
    "        \"rotated\": random_rotation(points),\n",
    "        \"scaled\": random_scaling(points),\n",
    "        \"jittered\": random_jittering(points),\n",
    "        \"elastic\": elastic_distortion(points),\n",
    "    }\n",
    "\n",
    "    # Select another random file for mixup and cutmix\n",
    "    mixup_file = random.choice(file_list)\n",
    "    cutmix_file = random.choice(file_list)\n",
    "    mixup_points, _ = load_point_cloud(os.path.join(input_dir, mixup_file))\n",
    "    cutmix_points, _ = load_point_cloud(os.path.join(input_dir, cutmix_file))\n",
    "\n",
    "    augmented_variants[\"mixup\"] = mixup(points, mixup_points[:4096])\n",
    "    augmented_variants[\"cutmix\"] = cutmix(points, cutmix_points[:4096])\n",
    "    augmented_variants[\"occluded\"] = occlusion_simulation(points)\n",
    "\n",
    "    # Ensure all augmented point clouds have exactly 4096 points\n",
    "    for key, aug_points in augmented_variants.items():\n",
    "        if aug_points.shape[0] < 4096:\n",
    "            aug_points = np.pad(aug_points, ((0, 4096 - aug_points.shape[0]), (0, 0)), mode='edge')\n",
    "        elif aug_points.shape[0] > 4096:\n",
    "            aug_points = aug_points[:4096]\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"aug_{key}{file_name[:-4]}.ply\")\n",
    "        save_point_cloud(aug_points, pcd_template, output_path)\n"
   ],
   "id": "aaa987eedf597aea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:32:23.703979Z",
     "start_time": "2025-02-13T15:31:47.779033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Encoder",
   "id": "371b8c5b261a5b2c"
  },
  {
   "metadata": {
    "id": "c75383b54d3cec85",
    "ExecuteTime": {
     "end_time": "2025-02-13T15:32:23.746322Z",
     "start_time": "2025-02-13T15:32:23.718811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PointNetPPEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(PointNetPPEncoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Shared MLPs for local feature extraction\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 1)\n",
    "        self.conv4 = nn.Conv1d(256, 512, 1)\n",
    "        self.conv5 = nn.Conv1d(512, 1024, 1)\n",
    "        self.conv6 = nn.Conv1d(1024, 2048, 1)\n",
    "\n",
    "        # Fully connected layers for global features\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc_mu = nn.Linear(256, latent_dim)       # Mean of latent distribution\n",
    "        self.fc_log_sigma = nn.Linear(256, latent_dim)  # Log variance of latent distribution\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x: (batch_size, num_points, 3)\n",
    "        x = x.permute(0, 2, 1)  # Change to (batch_size, 3, num_points)\n",
    "\n",
    "        # Apply shared MLPs\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "\n",
    "        # Global max pooling\n",
    "        x = torch.max(x, dim=2)[0]  # (batch_size, 256)\n",
    "\n",
    "        # Fully connected layers for latent representation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        mu = self.fc_mu(x)           # (batch_size, latent_dim)\n",
    "        log_sigma = self.fc_log_sigma(x)  # (batch_size, latent_dim)\n",
    "        return mu, log_sigma"
   ],
   "id": "c75383b54d3cec85",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "61f36e88b8196ee9"
   },
   "cell_type": "markdown",
   "source": [
    "Decoder"
   ],
   "id": "61f36e88b8196ee9"
  },
  {
   "metadata": {
    "id": "64d7136b58bb5243",
    "ExecuteTime": {
     "end_time": "2025-02-13T15:32:23.770942Z",
     "start_time": "2025-02-13T15:32:23.751846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PointNetPPDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128, num_points=4096):\n",
    "        super(PointNetPPDecoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_points = num_points\n",
    "\n",
    "        # Fully connected layers to create an initial coarse point cloud\n",
    "        self.fc1 = nn.Linear(latent_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)  # Coarse point cloud (e.g., 256 points * 3)\n",
    "\n",
    "        # Upsampling layers for finer details\n",
    "        self.fc4 = nn.Linear(1024, 2048)\n",
    "        self.fc5 = nn.Linear(2048, 4096)\n",
    "        self.fc6 = nn.Linear(4096, num_points * 3) # Final high-resolution output\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Input z: (batch_size, latent_dim)\n",
    "        x = F.relu(self.fc1(z))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))  # Coarse point cloud\n",
    "\n",
    "        # Upsample to finer resolution\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)  # (batch_size, num_points * 3)\n",
    "\n",
    "        # Reshape to point cloud format\n",
    "        x = x.view(-1, self.num_points, 3)  # (batch_size, num_points, 3)\n",
    "        return x"
   ],
   "id": "64d7136b58bb5243",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "id": "758790acbb9d4d71"
   },
   "cell_type": "markdown",
   "source": [
    "Reparameterization trick"
   ],
   "id": "758790acbb9d4d71"
  },
  {
   "metadata": {
    "id": "13b003faaa5cf90a",
    "ExecuteTime": {
     "end_time": "2025-02-13T15:32:23.791082Z",
     "start_time": "2025-02-13T15:32:23.775952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reparameterize(mu, log_sigma):\n",
    "    \"\"\"\n",
    "    Reparameterization trick to sample latent variable z.\n",
    "    z = mu + eps * exp(log_sigma * 0.5)\n",
    "    \"\"\"\n",
    "    std = torch.exp(0.5 * log_sigma)\n",
    "    epsilon = torch.randn_like(std)\n",
    "    return mu + epsilon * std"
   ],
   "id": "13b003faaa5cf90a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "id": "f9bd0df85b8a947e"
   },
   "cell_type": "markdown",
   "source": [
    "Encoder + Decoder + Reparameterization Trick = Autoencoder (in our case, Variational Autoencoder because we have mu and log sigma)"
   ],
   "id": "f9bd0df85b8a947e"
  },
  {
   "metadata": {
    "id": "5bfd8c367e909d47",
    "ExecuteTime": {
     "end_time": "2025-02-13T15:32:23.816019Z",
     "start_time": "2025-02-13T15:32:23.796093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PointNetPPAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128, num_points=4096):\n",
    "        super(PointNetPPAutoencoder, self).__init__()\n",
    "        self.encoder = PointNetPPEncoder(latent_dim)\n",
    "        self.decoder = PointNetPPDecoder(latent_dim, num_points)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "          reconstructed: (batch_size, num_points, 3)\n",
    "          mu: (batch_size, latent_dim)\n",
    "          log_sigma: (batch_size, latent_dim)\n",
    "        \"\"\"\n",
    "        mu, log_sigma = self.encoder(x)\n",
    "        z = reparameterize(mu, log_sigma)  # <-- Use the reparam trick\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed, mu, log_sigma"
   ],
   "id": "5bfd8c367e909d47",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "c418aab24fb6cd1a"
   },
   "cell_type": "markdown",
   "source": [
    "Loss Functions"
   ],
   "id": "c418aab24fb6cd1a"
  },
  {
   "metadata": {
    "id": "5937ef03469c762",
    "ExecuteTime": {
     "end_time": "2025-02-13T15:32:23.836378Z",
     "start_time": "2025-02-13T15:32:23.822531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chamfer_distance(x, y):\n",
    "    \"\"\"\n",
    "    Compute Chamfer Distance between two point clouds x and y.\n",
    "    \"\"\"\n",
    "    x_expanded = x.unsqueeze(2)  # (batch_size, num_points_x, 1, 3)\n",
    "    y_expanded = y.unsqueeze(1)  # (batch_size, 1, num_points_y, 3)\n",
    "    distances = torch.norm(x_expanded - y_expanded, dim=3)  # Pairwise distances\n",
    "    min_dist_x = torch.min(distances, dim=2)[0]\n",
    "    min_dist_y = torch.min(distances, dim=1)[0]\n",
    "    return torch.mean(min_dist_x) + torch.mean(min_dist_y)\n",
    "\n",
    "def kl_divergence(mu, log_sigma):\n",
    "    \"\"\"\n",
    "    Compute the KL divergence between the encoder's latent distribution and a standard Gaussian.\n",
    "    Args:\n",
    "        mu: Mean of the latent distribution (batch_size, latent_dim)\n",
    "        log_sigma: Log of standard deviation (batch_size, latent_dim)\n",
    "    Returns:\n",
    "        kl_loss: The KL divergence loss (scalar)\n",
    "    \"\"\"\n",
    "    kl_loss = -0.5 * torch.sum(1 + log_sigma - mu.pow(2) - log_sigma.exp(), dim=1)\n",
    "    return torch.mean(kl_loss)  # Return the batch mean"
   ],
   "id": "5937ef03469c762",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install open3d"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6LVz21MN1Lw",
    "outputId": "27ebab2c-6f98-4f4f-d90a-bfcdeaca566e",
    "ExecuteTime": {
     "end_time": "2025-02-13T01:27:22.406581Z",
     "start_time": "2025-02-13T01:27:17.781189Z"
    }
   },
   "id": "L6LVz21MN1Lw",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: open3d in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (0.18.0+c0be4a6)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.18.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from open3d) (1.26.4)\n",
      "Requirement already satisfied: dash>=2.6.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from open3d) (2.18.2)\n",
      "Requirement already satisfied: werkzeug>=3.0.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from open3d) (3.0.6)\n",
      "Requirement already satisfied: flask>=3.0.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from open3d) (3.0.3)\n",
      "Requirement already satisfied: nbformat>=5.7.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from open3d) (5.10.4)\n",
      "Requirement already satisfied: configargparse in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from open3d) (1.7)\n",
      "Requirement already satisfied: ipywidgets>=8.0.4 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from open3d) (8.1.5)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from dash>=2.6.0->open3d) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from dash>=2.6.0->open3d) (5.0.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from dash>=2.6.0->open3d) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from dash>=2.6.0->open3d) (4.12.2)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from dash>=2.6.0->open3d) (2.32.3)\n",
      "Requirement already satisfied: retrying in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from dash>=2.6.0->open3d) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from dash>=2.6.0->open3d) (75.6.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from flask>=3.0.0->open3d) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from flask>=3.0.0->open3d) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (3.0.13)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from nbformat>=5.7.0->open3d) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from werkzeug>=3.0.0->open3d) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from click>=8.1.3->flask>=3.0.0->open3d) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.18.0)\n",
      "Requirement already satisfied: stack_data in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.6.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.22.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (308)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (9.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (24.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from retrying->dash>=2.6.0->open3d) (1.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\admin\\tokyo-pointcloud\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "id": "e5489591ca3a5bfe",
    "ExecuteTime": {
     "end_time": "2025-02-13T01:27:24.414998Z",
     "start_time": "2025-02-13T01:27:22.409601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import open3d as o3d\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "class PointCloudDataset(data.Dataset):\n",
    "    def __init__(self, folder_path, num_points=4096):\n",
    "        self.folder_path = folder_path\n",
    "        self.num_points = num_points\n",
    "        self.files = [f for f in os.listdir(folder_path) if f.endswith('.ply')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.folder_path, self.files[idx])\n",
    "        pcd = o3d.io.read_point_cloud(file_path)\n",
    "        points = np.asarray(pcd.points)\n",
    "\n",
    "        # Scale and center the point cloud to fit within a unit cube or sphere:\n",
    "        points -= np.mean(points, axis=0)  # Center\n",
    "        # points /= np.max(np.linalg.norm(points, axis=1))  # I chose not to scale since I would like to see if my latent space can predict for height\n",
    "\n",
    "        # Randomly sample or pad points to ensure uniformity\n",
    "        if points.shape[0] > self.num_points:\n",
    "            indices = np.random.choice(points.shape[0], self.num_points, replace=False)\n",
    "            points = points[indices]\n",
    "        elif points.shape[0] < self.num_points:\n",
    "            pad_size = self.num_points - points.shape[0]\n",
    "            pad_points = np.zeros((pad_size, 3))\n",
    "            points = np.vstack((points, pad_points))\n",
    "\n",
    "        return torch.tensor(points, dtype=torch.float32)\n"
   ],
   "id": "e5489591ca3a5bfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "f7eefcfeb45ad53e"
   },
   "cell_type": "markdown",
   "source": [
    "Data Loader"
   ],
   "id": "f7eefcfeb45ad53e"
  },
  {
   "metadata": {
    "id": "a1885fb241f2426",
    "ExecuteTime": {
     "end_time": "2025-02-13T01:27:24.424602Z",
     "start_time": "2025-02-13T01:27:24.418011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "def get_data_loaders(folder_path=\"/content/drive/MyDrive/buildings_pointcloud_ply\",\n",
    "                     num_points=4096,\n",
    "                     batch_size=32,\n",
    "                     train_ratio=0.9,\n",
    "                     random_seed=42):  # Added a seed parameter for reproducibility\n",
    "    # Set the random seed for reproducibility\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    dataset = PointCloudDataset(folder_path, num_points=num_points)\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(f\"Dataset split: {len(train_dataset)} train samples, {len(test_dataset)} test samples\")\n",
    "    return train_loader, test_loader\n",
    "\n"
   ],
   "id": "a1885fb241f2426",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "id": "66eeedc6483e5548"
   },
   "cell_type": "markdown",
   "source": [
    "Define Training Loop"
   ],
   "id": "66eeedc6483e5548"
  },
  {
   "metadata": {
    "id": "97f721ebb7ec8945",
    "ExecuteTime": {
     "end_time": "2025-02-13T01:27:25.559999Z",
     "start_time": "2025-02-13T01:27:24.665264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(folder_path=\"/content/drive/MyDrive/buildings_pointcloud_ply\",\n",
    "                latent_dim=128,\n",
    "                num_points=4096,\n",
    "                batch_size=16,\n",
    "                num_epochs=50,\n",
    "                learning_rate=0.001,\n",
    "                beta=1.0,\n",
    "                device=\"cpu\"):\n",
    "\n",
    "    # Prepare data\n",
    "    train_loader, test_loader = get_data_loaders(\n",
    "        folder_path=folder_path,\n",
    "        num_points=num_points,\n",
    "        batch_size=batch_size,\n",
    "        train_ratio=0.9\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    model = PointNetPPAutoencoder(latent_dim=latent_dim, num_points=num_points)\n",
    "    model.to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    loss_history = []\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass (with VAE components)\n",
    "            reconstructed, mu, log_sigma = model(batch)\n",
    "\n",
    "            # Compute losses\n",
    "            recon_loss = chamfer_distance(reconstructed, batch)\n",
    "            kld_loss = kl_divergence(mu, log_sigma)\n",
    "\n",
    "            # Total loss (VAE) (which is equal to B=1)\n",
    "            loss = recon_loss + kld_loss\n",
    "\n",
    "            # Total loss (beta-VAE)\n",
    "            # loss = recon_loss + beta * kld_loss\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        loss_history.append(avg_epoch_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "        # Save the trained model\n",
    "        model_save_path = \"pointnetpp_VAE.pth\"\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Plot loss history\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), loss_history, marker='o', linestyle='-')\n",
    "    plt.title(\"Training Loss Over Epochs (Chamfer + KL)\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ],
   "id": "97f721ebb7ec8945",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "id": "85b90f670ce754"
   },
   "cell_type": "markdown",
   "source": [
    "Train"
   ],
   "id": "85b90f670ce754"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5085853a66ecc7f6",
    "outputId": "9085a3a4-a3d7-4a5f-932d-2fab3ee9044e"
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset split: 3606 train samples, 401 test samples\n",
      "Starting training...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1/50: 100%|██████████| 226/226 [48:50<00:00, 12.97s/it, Batch Loss=5.87]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50, Loss: 5.4949\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 2/50: 100%|██████████| 226/226 [00:22<00:00,  9.86it/s, Batch Loss=6.72]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2/50, Loss: 4.9826\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 3/50: 100%|██████████| 226/226 [00:24<00:00,  9.41it/s, Batch Loss=7.43]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3/50, Loss: 5.0797\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 4/50: 100%|██████████| 226/226 [00:23<00:00,  9.45it/s, Batch Loss=12.1]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4/50, Loss: 4.9152\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 5/50: 100%|██████████| 226/226 [00:23<00:00,  9.52it/s, Batch Loss=4.43]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5/50, Loss: 5.0297\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 6/50: 100%|██████████| 226/226 [00:23<00:00,  9.52it/s, Batch Loss=4.74]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6/50, Loss: 4.8606\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 7/50: 100%|██████████| 226/226 [00:23<00:00,  9.50it/s, Batch Loss=6.5]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7/50, Loss: 4.9394\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 8/50: 100%|██████████| 226/226 [00:23<00:00,  9.56it/s, Batch Loss=4.67]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8/50, Loss: 4.8016\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 9/50: 100%|██████████| 226/226 [00:23<00:00,  9.50it/s, Batch Loss=3.31]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9/50, Loss: 4.7959\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 10/50: 100%|██████████| 226/226 [00:23<00:00,  9.55it/s, Batch Loss=3.44]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10/50, Loss: 4.6817\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 11/50: 100%|██████████| 226/226 [00:23<00:00,  9.72it/s, Batch Loss=2.88]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 11/50, Loss: 4.7010\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 12/50: 100%|██████████| 226/226 [00:23<00:00,  9.58it/s, Batch Loss=3.65]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 12/50, Loss: 4.7372\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 13/50: 100%|██████████| 226/226 [00:23<00:00,  9.53it/s, Batch Loss=5.35]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 13/50, Loss: 4.7096\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 14/50: 100%|██████████| 226/226 [00:23<00:00,  9.55it/s, Batch Loss=3.34]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 14/50, Loss: 4.6883\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 15/50: 100%|██████████| 226/226 [00:23<00:00,  9.55it/s, Batch Loss=5.02]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 15/50, Loss: 4.7152\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 16/50: 100%|██████████| 226/226 [00:23<00:00,  9.52it/s, Batch Loss=3.95]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 16/50, Loss: 4.6784\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 17/50: 100%|██████████| 226/226 [00:23<00:00,  9.75it/s, Batch Loss=3.9]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 17/50, Loss: 4.6591\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 18/50: 100%|██████████| 226/226 [00:23<00:00,  9.62it/s, Batch Loss=3.32]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 18/50, Loss: 4.7275\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 19/50: 100%|██████████| 226/226 [00:23<00:00,  9.59it/s, Batch Loss=2.43]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 19/50, Loss: 4.6416\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 20/50: 100%|██████████| 226/226 [00:23<00:00,  9.62it/s, Batch Loss=3.5]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 20/50, Loss: 4.6505\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 21/50: 100%|██████████| 226/226 [00:23<00:00,  9.65it/s, Batch Loss=3.14]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 21/50, Loss: 4.6469\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 22/50: 100%|██████████| 226/226 [00:23<00:00,  9.60it/s, Batch Loss=5.25]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 22/50, Loss: 4.6665\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 23/50: 100%|██████████| 226/226 [00:23<00:00,  9.62it/s, Batch Loss=5.02]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 23/50, Loss: 4.6569\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 24/50: 100%|██████████| 226/226 [00:23<00:00,  9.61it/s, Batch Loss=2.72]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 24/50, Loss: 4.6225\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 25/50: 100%|██████████| 226/226 [00:23<00:00,  9.58it/s, Batch Loss=3.62]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 25/50, Loss: 4.6415\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 26/50: 100%|██████████| 226/226 [00:23<00:00,  9.59it/s, Batch Loss=4.63]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 26/50, Loss: 4.6094\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 27/50: 100%|██████████| 226/226 [00:23<00:00,  9.54it/s, Batch Loss=4.23]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 27/50, Loss: 4.6447\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 28/50: 100%|██████████| 226/226 [00:23<00:00,  9.64it/s, Batch Loss=4.3]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 28/50, Loss: 4.6859\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 29/50: 100%|██████████| 226/226 [00:23<00:00,  9.51it/s, Batch Loss=5.67]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 29/50, Loss: 4.6141\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 30/50: 100%|██████████| 226/226 [00:23<00:00,  9.56it/s, Batch Loss=3.69]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 30/50, Loss: 4.6378\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 31/50: 100%|██████████| 226/226 [00:23<00:00,  9.58it/s, Batch Loss=12.2]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 31/50, Loss: 4.6368\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 32/50: 100%|██████████| 226/226 [00:23<00:00,  9.57it/s, Batch Loss=3.29]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 32/50, Loss: 4.6461\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 33/50: 100%|██████████| 226/226 [00:23<00:00,  9.59it/s, Batch Loss=4]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 33/50, Loss: 4.6188\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 34/50: 100%|██████████| 226/226 [00:23<00:00,  9.55it/s, Batch Loss=3.96]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 34/50, Loss: 4.5937\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 35/50: 100%|██████████| 226/226 [00:23<00:00,  9.62it/s, Batch Loss=3.15]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 35/50, Loss: 4.5744\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 36/50: 100%|██████████| 226/226 [00:23<00:00,  9.55it/s, Batch Loss=6.69]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 36/50, Loss: 4.6877\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 37/50: 100%|██████████| 226/226 [00:23<00:00,  9.58it/s, Batch Loss=3.39]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 37/50, Loss: 4.6103\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 38/50: 100%|██████████| 226/226 [00:23<00:00,  9.63it/s, Batch Loss=3.17]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 38/50, Loss: 4.6172\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 39/50: 100%|██████████| 226/226 [00:23<00:00,  9.59it/s, Batch Loss=3.51]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 39/50, Loss: 4.6195\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 40/50: 100%|██████████| 226/226 [00:23<00:00,  9.68it/s, Batch Loss=7.05]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 40/50, Loss: 4.6070\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 41/50: 100%|██████████| 226/226 [00:23<00:00,  9.57it/s, Batch Loss=6.1]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 41/50, Loss: 4.6137\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 42/50: 100%|██████████| 226/226 [00:23<00:00,  9.57it/s, Batch Loss=9.97]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 42/50, Loss: 4.5620\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 43/50: 100%|██████████| 226/226 [00:23<00:00,  9.61it/s, Batch Loss=4.48]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 43/50, Loss: 4.6115\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 44/50: 100%|██████████| 226/226 [00:23<00:00,  9.59it/s, Batch Loss=4.28]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 44/50, Loss: 4.6042\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 45/50: 100%|██████████| 226/226 [00:23<00:00,  9.69it/s, Batch Loss=3.51]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 45/50, Loss: 4.5717\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 46/50: 100%|██████████| 226/226 [00:23<00:00,  9.59it/s, Batch Loss=4.07]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 46/50, Loss: 4.5837\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 47/50: 100%|██████████| 226/226 [00:23<00:00,  9.62it/s, Batch Loss=3.84]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 47/50, Loss: 4.5335\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 48/50: 100%|██████████| 226/226 [00:23<00:00,  9.57it/s, Batch Loss=4.33]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 48/50, Loss: 4.5788\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 49/50: 100%|██████████| 226/226 [00:23<00:00,  9.61it/s, Batch Loss=3.39]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 49/50, Loss: 4.5961\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 50/50: 100%|██████████| 226/226 [00:23<00:00,  9.60it/s, Batch Loss=4.14]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 50/50, Loss: 4.5606\n",
      "Model saved to pointnetpp_VAE.pth\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "execution_count": 16,
   "source": [
    "train_model(\n",
    "    folder_path=\"/content/drive/MyDrive/buildings_pointcloud_ply\",\n",
    "    latent_dim=128,\n",
    "    num_points=4096,\n",
    "    batch_size=16,\n",
    "    num_epochs=50,\n",
    "    learning_rate=0.001,\n",
    "    beta=1.0,\n",
    "    device=\"cuda\"  # or \"cuda\" if you have a GPU\n",
    ")"
   ],
   "id": "5085853a66ecc7f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T01:27:46.687129Z",
     "start_time": "2025-02-13T01:27:46.675227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch\n",
    "\n",
    "def visualize_input_and_reconstructed(model, test_loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get the first batch from the test_loader\n",
    "        for batch in test_loader:\n",
    "            # Shape of batch: (batch_size, num_points, 3)\n",
    "            batch = batch.to(device)\n",
    "            break  # Just get the first batch\n",
    "\n",
    "        # Let's visualize the first point cloud in this batch\n",
    "        input_pc = batch[0]  # shape: (num_points, 3)\n",
    "        input_np = input_pc.cpu().numpy()  # Convert to numpy for open3d\n",
    "\n",
    "        # Encode and decode the point cloud\n",
    "        mu, log_sigma = model.encoder(input_pc.unsqueeze(0))  # add batch dim => (1, num_points, 3)\n",
    "        z = reparameterize(mu, log_sigma)\n",
    "        reconstructed = model.decoder(z)  # shape: (1, num_points, 3)\n",
    "\n",
    "        # Convert reconstructed to numpy\n",
    "        reconstructed_np = reconstructed[0].cpu().numpy()\n",
    "\n",
    "    # Create Open3D point cloud for the input\n",
    "    pcd_input = o3d.geometry.PointCloud()\n",
    "    pcd_input.points = o3d.utility.Vector3dVector(input_np)\n",
    "    # Color the input cloud red\n",
    "    pcd_input.paint_uniform_color([1.0, 0.0, 0.0])\n",
    "\n",
    "    # Create Open3D point cloud for the reconstructed shape\n",
    "    pcd_reconstructed = o3d.geometry.PointCloud()\n",
    "    pcd_reconstructed.points = o3d.utility.Vector3dVector(reconstructed_np)\n",
    "    # Color the reconstructed cloud green\n",
    "    pcd_reconstructed.paint_uniform_color([0.0, 1.0, 0.0])\n",
    "\n",
    "    # (Optional) Shift the reconstructed cloud so it’s easier to see side by side\n",
    "    shift_along_x = 1.0\n",
    "    pcd_reconstructed.translate((shift_along_x, 0, 0))\n",
    "\n",
    "    # Visualize both point clouds together\n",
    "    o3d.visualization.draw_geometries([pcd_input, pcd_reconstructed])"
   ],
   "id": "2a919bae36ec64a1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "import open3d as o3d\n",
    "import torch\n",
    "\n",
    "model = PointNetPPAutoencoder(latent_dim=128, num_points=4096)\n",
    "model.load_state_dict(torch.load(\"pointnetpp_VAE_with_Distance_Loss.pth\", map_location=torch.device(\"cpu\")))\n",
    "\n",
    "model.to(\"cpu\")  # or \"cuda\"\n",
    "\n",
    "train_loader, test_loader = get_data_loaders(\n",
    "    folder_path=r\"C:\\Users\\Admin\\PycharmProjects\\AI-Projects\\Tokyo-PointCloud\\buildings_pointcloud_ply\",\n",
    "    num_points=4096,\n",
    "    batch_size=4,  # or 1, if you want just one per batch\n",
    "    train_ratio=0.9\n",
    ")\n",
    "\n",
    "visualize_input_and_reconstructed(model, test_loader, device=\"cpu\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UlFB72w3e5yY",
    "outputId": "adc9212b-192d-40cd-ba7c-6392a4668f6c",
    "ExecuteTime": {
     "end_time": "2025-02-13T01:35:58.729140Z",
     "start_time": "2025-02-13T01:34:16.777447Z"
    }
   },
   "id": "UlFB72w3e5yY",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: 3606 train samples, 401 test samples\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Load your trained (beta-)VAE model\n",
    "# ---------------------------\n",
    "\n",
    "# Load model\n",
    "model = PointNetPPAutoencoder(latent_dim=128, num_points=4096)\n",
    "model.load_state_dict(torch.load('pointnetpp_VAE.pth'))\n",
    "model = model.to('cuda')  # Ensure the model is moved to GPU\n",
    "model.eval()\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Prepare (or load) the dataset\n",
    "# ---------------------------\n",
    "# Assuming train_loader yields only `inputs`, which are point clouds.\n",
    "all_latents = []\n",
    "\n",
    "for inputs in train_loader:  # No labels\n",
    "    inputs = inputs.to('cuda')  # Use 'cuda' if you have a GPU and the model is on GPU\n",
    "    with torch.no_grad():\n",
    "        z_mean, z_logvar = model.encoder(inputs)  # Call the encoder directly\n",
    "\n",
    "        # Sample from Gaussian distribution using reparameterization trick\n",
    "        std = torch.exp(0.5 * z_logvar)\n",
    "        eps = torch.randn_like(std)  # Gaussian noise\n",
    "        z_vec = z_mean + eps * std  # Sampled latent vector\n",
    "\n",
    "    all_latents.append(z_vec.cpu().numpy())\n",
    "\n",
    "all_latents = np.concatenate(all_latents, axis=0)  # shape: (N, latent_dim)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Apply t-SNE (or UMAP) to reduce dimensionality\n",
    "# ---------------------------\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "latents_2d = tsne.fit_transform(all_latents)  # shape: (N, 2)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Plot the 2D t-SNE results\n",
    "# ---------------------------\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(latents_2d[:, 0], latents_2d[:, 1], s=5)  # No labels, so just plot the points\n",
    "plt.title(\"Latent Space Visualization (t-SNE)\")\n",
    "plt.xlabel(\"t-SNE Dim 1\")\n",
    "plt.ylabel(\"t-SNE Dim 2\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "id": "ptODu-K4eq4i",
    "outputId": "990e097e-b537-463b-8f6b-0f94ea51a26c",
    "ExecuteTime": {
     "end_time": "2025-01-28T00:33:43.341822Z",
     "start_time": "2025-01-28T00:33:37.563865Z"
    }
   },
   "id": "ptODu-K4eq4i",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23424\\1931494308.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('pointnetpp_VAE.pth'))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 12\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# ---------------------------\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# 1. Load your trained (beta-)VAE model\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# ---------------------------\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Load model\u001B[39;00m\n\u001B[0;32m     11\u001B[0m model \u001B[38;5;241m=\u001B[39m PointNetPPAutoencoder(latent_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, num_points\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4096\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpointnetpp_VAE.pth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     13\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)  \u001B[38;5;66;03m# Ensure the model is moved to GPU\u001B[39;00m\n\u001B[0;32m     14\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32m~\\Tokyo-PointCloud\\venv\\Lib\\site-packages\\torch\\serialization.py:1360\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1358\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1359\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(_get_wo_message(\u001B[38;5;28mstr\u001B[39m(e))) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1360\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1361\u001B[0m \u001B[43m            \u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1362\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1363\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1364\u001B[0m \u001B[43m            \u001B[49m\u001B[43moverall_storage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverall_storage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1365\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1366\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1367\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n\u001B[0;32m   1368\u001B[0m     f_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(f, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\Tokyo-PointCloud\\venv\\Lib\\site-packages\\torch\\serialization.py:1848\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1846\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m _serialization_tls\n\u001B[0;32m   1847\u001B[0m _serialization_tls\u001B[38;5;241m.\u001B[39mmap_location \u001B[38;5;241m=\u001B[39m map_location\n\u001B[1;32m-> 1848\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1849\u001B[0m _serialization_tls\u001B[38;5;241m.\u001B[39mmap_location \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1851\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n",
      "File \u001B[1;32m~\\Tokyo-PointCloud\\venv\\Lib\\site-packages\\torch\\serialization.py:1812\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[1;34m(saved_id)\u001B[0m\n\u001B[0;32m   1810\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1811\u001B[0m     nbytes \u001B[38;5;241m=\u001B[39m numel \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_element_size(dtype)\n\u001B[1;32m-> 1812\u001B[0m     typed_storage \u001B[38;5;241m=\u001B[39m \u001B[43mload_tensor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1813\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_maybe_decode_ascii\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1814\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1816\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m typed_storage\n",
      "File \u001B[1;32m~\\Tokyo-PointCloud\\venv\\Lib\\site-packages\\torch\\serialization.py:1784\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[1;34m(dtype, numel, key, location)\u001B[0m\n\u001B[0;32m   1779\u001B[0m         storage\u001B[38;5;241m.\u001B[39mbyteswap(dtype)\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001B[39;00m\n\u001B[0;32m   1782\u001B[0m \u001B[38;5;66;03m# stop wrapping with TypedStorage\u001B[39;00m\n\u001B[0;32m   1783\u001B[0m typed_storage \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstorage\u001B[38;5;241m.\u001B[39mTypedStorage(\n\u001B[1;32m-> 1784\u001B[0m     wrap_storage\u001B[38;5;241m=\u001B[39m\u001B[43mrestore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m   1785\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   1786\u001B[0m     _internal\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   1787\u001B[0m )\n\u001B[0;32m   1789\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typed_storage\u001B[38;5;241m.\u001B[39m_data_ptr() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1790\u001B[0m     loaded_storages[key] \u001B[38;5;241m=\u001B[39m typed_storage\n",
      "File \u001B[1;32m~\\Tokyo-PointCloud\\venv\\Lib\\site-packages\\torch\\serialization.py:601\u001B[0m, in \u001B[0;36mdefault_restore_location\u001B[1;34m(storage, location)\u001B[0m\n\u001B[0;32m    581\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    582\u001B[0m \u001B[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001B[39;00m\n\u001B[0;32m    583\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    598\u001B[0m \u001B[38;5;124;03m       all matching ones return `None`.\u001B[39;00m\n\u001B[0;32m    599\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    600\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[1;32m--> 601\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    602\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    603\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\Tokyo-PointCloud\\venv\\Lib\\site-packages\\torch\\serialization.py:539\u001B[0m, in \u001B[0;36m_deserialize\u001B[1;34m(backend_name, obj, location)\u001B[0m\n\u001B[0;32m    537\u001B[0m     backend_name \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_get_privateuse1_backend_name()\n\u001B[0;32m    538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m location\u001B[38;5;241m.\u001B[39mstartswith(backend_name):\n\u001B[1;32m--> 539\u001B[0m     device \u001B[38;5;241m=\u001B[39m \u001B[43m_validate_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    540\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "File \u001B[1;32m~\\Tokyo-PointCloud\\venv\\Lib\\site-packages\\torch\\serialization.py:508\u001B[0m, in \u001B[0;36m_validate_device\u001B[1;34m(location, backend_name)\u001B[0m\n\u001B[0;32m    506\u001B[0m     device_index \u001B[38;5;241m=\u001B[39m device\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;28;01mif\u001B[39;00m device\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(device_module, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_available\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m device_module\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m--> 508\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    509\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting to deserialize object on a \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbackend_name\u001B[38;5;241m.\u001B[39mupper()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    510\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdevice but torch.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbackend_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.is_available() is False. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    511\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf you are running on a CPU-only machine, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    512\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease use torch.load with map_location=torch.device(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    513\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto map your storages to the CPU.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    514\u001B[0m     )\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(device_module, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdevice_count\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    516\u001B[0m     device_count \u001B[38;5;241m=\u001B[39m device_module\u001B[38;5;241m.\u001B[39mdevice_count()\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:38:41.003530Z",
     "start_time": "2025-02-13T15:38:31.233279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = PointNetPPAutoencoder(latent_dim=128, num_points=4096)\n",
    "model.load_state_dict(torch.load(\"pointnetpp_VAE.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "dummy_input = torch.randn(1, 4096, 3)  # Adjust input shape based on your model\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\", opset_version=11, input_names=[\"input\"], output_names=[\"output\"])\n"
   ],
   "id": "98605b82261f56a5",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f1e0ad3b64329e10"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
